---
layout: post
title:  分布式协调之zookeeper学习一
date:   2019-03-04 21:52:12 +08:00
category: 高并发分布式
tags: zookeeper
comments: true
---

* content
{:toc}

ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。[zookeeper官网](http://zookeeper.apache.org/)












## 架构发展的起因

  以电商架构为例， 早期我们是单一的应用架构， 随着互联网的快速发展和体量的不断增长，后端的架构通过垂直伸缩的方式很难达到我们期望的性能要求，同时投入产出比也非常大，同时普通 PC 的性能也越来越高，所以通过水平伸缩的方式来提升性能成为了主流。

  在分布式架构下，当服务越来越多，规模越来越大时，对应的机器数量也越来越大，单靠人工来管理和维护服务及地址的配置地址信息会越来越困难， 单点故障的问题也开始凸显出来，一旦服务路由或者负载均衡服务器宕机，依赖他的所有服务均将失效。

  此时，需要一个能够动态注册和获取服务信息的地方。来统一管理服务名称和其对应的服务器列表信息，称之为服务配置中心。

  服务提供者在启动时，将其提供的服务名称、服务器地址注册到服务配置中心，服务消费者通过服务配置中心来获得需要调用的服务的机器列表。通过相应的负载均衡算法，选取其中一台服务器进行调用。当服务器宕机或者下线时，相应的机器需要能够动态地从服务配置中心里面移除，并通知相应的服务消费者，否则服务消费者就有可能因为调用到已经失效服务而发生错误，在这个过程中，服务消费者只有在第一次调用服务时需要查询服务配置中心， 然后将查询到的信息缓存到本地，后面的调用直接使用本地缓存的服务地址列表信息，而不需要重新发起请求道服务配置中心去获取相应的服务地址列表，直到服务的地址列表有变更（机器上线或者下线）。这种无中心化的结构解决了之前负载均衡设备所导致的单点故障问题，并且大大减轻了服务配置中心的压力。

## zookeeper

  - 概念

  zookeeper 是一个开源的分布式协调服务，由雅虎公司创建，是 google chubby 的开源实现。 zookeeper 的设计目标是将哪些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集（由若干条指令组成的，完成一定功能的一个过程），并且以一些列简单一用的接口提供给用户使用。

  - 安装

  zookeeper 有两种运行模式：集群模式和单击模式

  从http://apache.fayea.com/zookeeper/ 下载完成，通过 tar -zxvf 解压

  常用命令

  1 启动 ZK 服务:

    bin/zkServer.sh start

  2 查看 ZK 服务状态:

  bin/zkServer.sh status

  3 停止 ZK 服务:

  bin/zkServer.sh stop

  4 重启 ZK 服务:

  bin/zkServer.sh restart

  5 连接服务器

  zkCli.sh -timeout 0 -r -server ip:port

  单机环境安装

  一般情况下，在开发测试环境，没有这么多资源的情况下，而且也不需要特别好的稳定性的前提下，我们可以使用单机部署；

  初 次 使 用 zookeeper ， 需 要 将 conf 目 录 下 的zoo_sample.cfg 文件 copy 一份重命名为 zoo.cfg修改 dataDir 目录， dataDir 表示日志文件存放的路径

  集群环境安装

  在 zookeeper 集群中，各个节点总共有三种角色，分别是：leader， follower， observer集群模式我们采用模拟 3 台机器来搭建 zookeeper 集群。

  分别复制安装包到三台机器上并解压，同时 copy 一份zoo.cfg。

  1 修改配置文件

  修改端口
  server.1=IP1:2888:3888 【2888：访问 zookeeper 的端口；3888：重新选举 leader 的端口】
  server.2=IP2.2888:3888
  server.3=IP3.2888:2888

  server.A=B： C： D：其 中
  A 是一个数字，表示这个是第几号服务器；
  B 是这个服务器的 ip 地址；
  C 表示的是这个服务器与集群中的 Leader服务器交换信息的端口；
  D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。

  如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。

  在集群模式下，集群中每台机器都需要感知到整个集群是由哪几台机器组成的，在配置文件中，按照格式server.id=host:port:port，每一行代表一个机器配置

  id: 指的是 server ID,用来标识该机器在集群中的机器序号

  2 新建 datadir 目录，设置 myid

  在每台zookeeper机器上，我们都需要在数据目录(dataDir)下创建一个 myid 文件，该文件只有一行内容，对应每台机器的 Server ID 数字；比如 server.1 的 myid 文件内容就是1。【必须确保每个服务器的 myid 文件中的数字不同，并且和自己所在机器的 zoo.cfg 中 server.id 的 id 值一致， id 的范围是 1~255】

  3 启动 zookeeper

  带 Observer 角色的集群Observer：在不影响写性能的情况下扩展 zookeeper本身 zookeeper 的集群性能已经很好了，但是如果超大量的客户端访问，就势必需要增加 zookeeper 集群的服务器数量，而随着服务器的增加， zookeeper 集群的写性能就会下降； zookeeper 中 znode 的变更需要半数及以上服务器投票通过，而随着机器的增加，由于网络消耗等原因必定会导致投票成本增加。也就导致性能下降的结果
